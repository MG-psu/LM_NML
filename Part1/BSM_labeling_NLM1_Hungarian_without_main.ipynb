{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BsM LABELING WORKS FOR SINGLE NLM_file, NOT WORKING IN A LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22b5d760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f8268417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3095c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/LM_ten_for_clustering.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ab51bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a043c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "889e7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['tissue_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bf857bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%\n",
      "(8791, 979)\n",
      "{'Blasts and mononuclear cells, AML patient': 0, 'Breast Tumor': 1, 'HumanAorticEndothelialCells': 2, 'Leukemia patient sample': 3, 'Lymphoblastoid cell line': 4, 'PBMC': 5, 'airway epithelial cells obtained by bronchoscopy and brushing': 6, 'colon cancer tissue': 7, 'pre-treatment bone marrow': 8, 'primary colorectal adenocarcinoma': 9}\n",
      "&&&&&&&&&&&&&&&&&&&&&&\n",
      "[[ 1.31609287 -0.69996794  0.25155807 ... -1.46971929  0.81113671\n",
      "   0.4586737 ]\n",
      " [-0.09076701  0.32236922 -0.78161387 ...  0.36883122 -0.13308361\n",
      "   0.25409251]\n",
      " [-0.82147262 -0.47813704  0.37796664 ...  0.67170825  0.43928024\n",
      "  -0.1786765 ]\n",
      " ...\n",
      " [-0.7355156   0.82820047 -0.76553142 ... -0.43231842 -0.85123344\n",
      "   0.38013893]\n",
      " [-0.47439313 -0.91938106  0.10225269 ... -0.73638172  0.59809838\n",
      "   0.06296796]\n",
      " [-0.10276427 -0.40231664 -0.51419134 ...  0.32883577 -0.67206827\n",
      "   0.26743757]]\n",
      "indexes: [(0, 7), (1, 9), (2, 2), (3, 4), (4, 3), (5, 5), (6, 0), (7, 6), (8, 8), (9, 1)]\n",
      "actual labels: [7 7 7 ... 9 9 9]\n",
      "mapped labels: [6 6 6 ... 1 1 1]\n",
      "---------------------\n",
      "Hungarian method confusion matrix:\n",
      "\n",
      " [[ 522    0    0    3    0    0    0    0    0    0]\n",
      " [   3 1239    0    0    0    2    0    1    0  544]\n",
      " [   0    0 1014    0    0    0    0    0    0    0]\n",
      " [   3    0    0 1514    0    0    0  579    0    0]\n",
      " [   0    0    0    0  816    1    0    0    0    0]\n",
      " [ 512    0    0    0    0   21    0   17    0    0]\n",
      " [   0    0    0    0    0    0  333    0    0    0]\n",
      " [   0   44    0    0    0    0    0    0    0  287]\n",
      " [   0    1    0    1    0    0    0    3  812    0]\n",
      " [   0    0    0    0    0    0    0    0    0  519]]\n",
      "accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If we use (external) classification evalutation measures like F1 or \n",
    "accuracy for clustering evaluation, problems may arise. \n",
    "\n",
    "One way to fix is to perform label matching.\n",
    "\n",
    "Here we performs kmeans clustering on the Iris dataset and proceed to use \n",
    "the Hungarian (Munkres) algorithm to correct the mismatched labeling. \n",
    "'''\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from munkres import Munkres\n",
    "\n",
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    \"\"\"computes accuracy from confusion matrix\"\"\"\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "\n",
    "\"\"\"entry point\"\"\"\n",
    "dataset=pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/Initial_NLM/NLM1.csv')\n",
    "#dataset = pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/LM_ten_for_clustering.csv')# loads the dataset\n",
    "#data, classes = dataset.data, dataset.target # data and true labels\n",
    "unscaled_data=dataset.drop(['tissue_name'], axis=1)\n",
    "classes_actual=dataset['tissue_name']\n",
    "print(\"%%%%%%%%%%%%%%\")\n",
    "print(dataset.shape)   \n",
    "    \n",
    "#Standardizing\n",
    "sc=StandardScaler()\n",
    "data = sc.fit_transform(unscaled_data)\n",
    "#encoding tissie_name\n",
    "le = preprocessing.LabelEncoder()\n",
    "classes= le.fit_transform(classes_actual)\n",
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(le_name_mapping)\n",
    "    \n",
    "algo = KMeans(n_clusters=10, random_state = 0)\n",
    "\n",
    "labels = algo.fit(data).labels_ # performs the algo and get the predicted labels\n",
    "centroids=algo.cluster_centers_\n",
    "print(\"&&&&&&&&&&&&&&&&&&&&&&\")\n",
    "print(centroids)\n",
    "num_labels = len(np.unique(classes))\n",
    "\n",
    "cm = confusion_matrix(classes, labels, labels=range(num_labels)) # gets the confusion matrix\n",
    "#print (\"---------------------\\nold confusion matrix:\\n\" \\\n",
    "     #     \" %s\\naccuracy: %.2f\" % (str(cm), accuracy(cm)))\n",
    "\n",
    "cost_matrix = make_cost_matrix(labels, classes)\n",
    "\n",
    "m = Munkres()\n",
    "indexes = m.compute(cost_matrix)\n",
    "print(\"indexes:\", indexes)\n",
    "#     contmat = contingency_matrix(classes, labels)\n",
    "#     print(\"Here----\")\n",
    "#     print(m.compute(contmat.max()-contmat))\n",
    "mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "    #print (\"---------------------\\nmapping:\")\n",
    "    #for old, new in mapper['iteritems']:\n",
    "    #for old, new in mapper.iteritems():\n",
    "        \n",
    "        #print (\"map: %s --> %s\" %(old, new))\n",
    "\n",
    "new_labels = translate_clustering(labels, mapper)\n",
    "\n",
    "print(\"actual labels:\",labels)#actual labels\n",
    "print(\"mapped labels:\",new_labels)#mapped clustering labels\n",
    "new_cm = confusion_matrix(classes, new_labels, labels=range(num_labels))\n",
    "print (\"---------------------\\nHungarian method confusion matrix:\\n\\n\" \\\n",
    "          \" %s\\naccuracy: %.2f\" % (str(new_cm), accuracy(new_cm)))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e607fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_data= pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/bsm_2k_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6b48d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm=bsm_data.drop(['cid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c4195b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>217398_x_at</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>200045_at</th>\n",
       "      <th>200053_at</th>\n",
       "      <th>200071_at</th>\n",
       "      <th>200078_s_at</th>\n",
       "      <th>200083_at</th>\n",
       "      <th>200617_at</th>\n",
       "      <th>200621_at</th>\n",
       "      <th>...</th>\n",
       "      <th>221308_at</th>\n",
       "      <th>221478_at</th>\n",
       "      <th>221539_at</th>\n",
       "      <th>221562_s_at</th>\n",
       "      <th>222103_at</th>\n",
       "      <th>34408_at</th>\n",
       "      <th>36936_at</th>\n",
       "      <th>37152_at</th>\n",
       "      <th>40829_at</th>\n",
       "      <th>56197_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.9210</td>\n",
       "      <td>6.4805</td>\n",
       "      <td>8.1883</td>\n",
       "      <td>10.1831</td>\n",
       "      <td>8.5187</td>\n",
       "      <td>11.1252</td>\n",
       "      <td>10.0020</td>\n",
       "      <td>10.0832</td>\n",
       "      <td>8.8516</td>\n",
       "      <td>8.2504</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1157</td>\n",
       "      <td>7.7966</td>\n",
       "      <td>8.1964</td>\n",
       "      <td>5.6150</td>\n",
       "      <td>9.2706</td>\n",
       "      <td>6.0845</td>\n",
       "      <td>8.5853</td>\n",
       "      <td>7.2343</td>\n",
       "      <td>7.2533</td>\n",
       "      <td>11.3259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.9427</td>\n",
       "      <td>6.6415</td>\n",
       "      <td>8.7040</td>\n",
       "      <td>10.9209</td>\n",
       "      <td>9.8998</td>\n",
       "      <td>9.5091</td>\n",
       "      <td>11.4438</td>\n",
       "      <td>10.0322</td>\n",
       "      <td>8.6753</td>\n",
       "      <td>9.8107</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1149</td>\n",
       "      <td>7.6191</td>\n",
       "      <td>8.7248</td>\n",
       "      <td>5.8247</td>\n",
       "      <td>7.6989</td>\n",
       "      <td>6.0541</td>\n",
       "      <td>9.2437</td>\n",
       "      <td>6.7825</td>\n",
       "      <td>7.9849</td>\n",
       "      <td>11.4891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.9440</td>\n",
       "      <td>6.6642</td>\n",
       "      <td>8.3699</td>\n",
       "      <td>11.3780</td>\n",
       "      <td>10.1662</td>\n",
       "      <td>9.1081</td>\n",
       "      <td>11.5052</td>\n",
       "      <td>10.2779</td>\n",
       "      <td>9.6829</td>\n",
       "      <td>9.6168</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3738</td>\n",
       "      <td>7.7441</td>\n",
       "      <td>9.0112</td>\n",
       "      <td>5.2177</td>\n",
       "      <td>7.8978</td>\n",
       "      <td>6.4360</td>\n",
       "      <td>9.0888</td>\n",
       "      <td>6.9541</td>\n",
       "      <td>8.3431</td>\n",
       "      <td>11.4972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.9481</td>\n",
       "      <td>7.9483</td>\n",
       "      <td>9.0812</td>\n",
       "      <td>11.0657</td>\n",
       "      <td>10.3749</td>\n",
       "      <td>9.6479</td>\n",
       "      <td>11.4184</td>\n",
       "      <td>10.7670</td>\n",
       "      <td>10.0884</td>\n",
       "      <td>10.2380</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4395</td>\n",
       "      <td>7.0624</td>\n",
       "      <td>9.2065</td>\n",
       "      <td>4.6060</td>\n",
       "      <td>8.0007</td>\n",
       "      <td>6.3789</td>\n",
       "      <td>9.2471</td>\n",
       "      <td>7.5520</td>\n",
       "      <td>8.6685</td>\n",
       "      <td>11.9700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.9335</td>\n",
       "      <td>7.3172</td>\n",
       "      <td>8.8104</td>\n",
       "      <td>10.5564</td>\n",
       "      <td>9.6438</td>\n",
       "      <td>9.6520</td>\n",
       "      <td>10.5210</td>\n",
       "      <td>10.4148</td>\n",
       "      <td>9.0415</td>\n",
       "      <td>9.9689</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4521</td>\n",
       "      <td>11.4614</td>\n",
       "      <td>10.1346</td>\n",
       "      <td>7.0172</td>\n",
       "      <td>8.1928</td>\n",
       "      <td>6.5617</td>\n",
       "      <td>9.2092</td>\n",
       "      <td>8.0298</td>\n",
       "      <td>8.4564</td>\n",
       "      <td>11.9278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   217398_x_at  1007_s_at  121_at  200045_at  200053_at  200071_at  \\\n",
       "0      14.9210     6.4805  8.1883    10.1831     8.5187    11.1252   \n",
       "1      14.9427     6.6415  8.7040    10.9209     9.8998     9.5091   \n",
       "2      14.9440     6.6642  8.3699    11.3780    10.1662     9.1081   \n",
       "3      14.9481     7.9483  9.0812    11.0657    10.3749     9.6479   \n",
       "4      14.9335     7.3172  8.8104    10.5564     9.6438     9.6520   \n",
       "\n",
       "   200078_s_at  200083_at  200617_at  200621_at  ...  221308_at  221478_at  \\\n",
       "0      10.0020    10.0832     8.8516     8.2504  ...     4.1157     7.7966   \n",
       "1      11.4438    10.0322     8.6753     9.8107  ...     4.1149     7.6191   \n",
       "2      11.5052    10.2779     9.6829     9.6168  ...     4.3738     7.7441   \n",
       "3      11.4184    10.7670    10.0884    10.2380  ...     4.4395     7.0624   \n",
       "4      10.5210    10.4148     9.0415     9.9689  ...     4.4521    11.4614   \n",
       "\n",
       "   221539_at  221562_s_at  222103_at  34408_at  36936_at  37152_at  40829_at  \\\n",
       "0     8.1964       5.6150     9.2706    6.0845    8.5853    7.2343    7.2533   \n",
       "1     8.7248       5.8247     7.6989    6.0541    9.2437    6.7825    7.9849   \n",
       "2     9.0112       5.2177     7.8978    6.4360    9.0888    6.9541    8.3431   \n",
       "3     9.2065       4.6060     8.0007    6.3789    9.2471    7.5520    8.6685   \n",
       "4    10.1346       7.0172     8.1928    6.5617    9.2092    8.0298    8.4564   \n",
       "\n",
       "   56197_at  \n",
       "0   11.3259  \n",
       "1   11.4891  \n",
       "2   11.4972  \n",
       "3   11.9700  \n",
       "4   11.9278  \n",
       "\n",
       "[5 rows x 978 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aaa81673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code didn't work\n",
    "#to assign labels to new data based on centroids\n",
    "def Labs( newdata,centroids ):    \n",
    "    l = []\n",
    "    for i in range(len(newdata)):\n",
    "        m = []\n",
    "        for j in range(n):        \n",
    "            p = np.linalg.norm(newdata[(i),:]-centroids[(j),:])\n",
    "            m.append(p)\n",
    "        po = np.argmin(m)\n",
    "        l.append(po)\n",
    "    return pd.DataFrame(np.array(l) + 1,columns =['Lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a8ca8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_assignment(centroids, points):\n",
    "    num_centroids, dim = centroids.shape\n",
    "    num_points, _ = points.shape\n",
    "\n",
    "    # Tile and reshape both arrays into `[num_points, num_centroids, dim]`.                                                                      \n",
    "    centroids = np.tile(centroids, [num_points, 1]).reshape([num_points, num_centroids, dim])\n",
    "    points = np.tile(points, [1, num_centroids]).reshape([num_points, num_centroids, dim])\n",
    "\n",
    "    # Compute all distances (for all points and all centroids) at once and                                                                       \n",
    "    # select the min centroid for each point.                                                                                                    \n",
    "    distances = np.sum(np.square(centroids - points), axis=2)\n",
    "    return np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cd18be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsm_lab=kmeans_assignment(centroids, bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a2daae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 3, 5, 8}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(bsm_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3888139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labs(bsm, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c45e10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_assignment2(centroids, points):\n",
    "    P, C = points.shape[0], centroids.shape[0]\n",
    "    distances = np.zeros((P, C), dtype=np.float32)\n",
    "    for p in range(P):\n",
    "        for c in range(C):\n",
    "            distances[p, c] = np.sum(np.square(centroids[c] - points[p]))\n",
    "    return np.argmin(distances, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4047435d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkmeans_assignment2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36mkmeans_assignment2\u001b[0;34m(centroids, points)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(P):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(C):\n\u001b[0;32m----> 6\u001b[0m         distances[p, c] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39msquare(centroids[c] \u001b[38;5;241m-\u001b[39m \u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39margmin(distances, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "kmeans_assignment2(centroids, bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424050fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
###https://www.hungarianalgorithm.com/examplehungarianalgorithm.php ###
