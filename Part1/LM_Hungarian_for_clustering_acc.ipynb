#credits: https://github.com/siolag161/blog/blob/master/content/label-matching-for-clustering-evaluation.md ##

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22b5d760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8268417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3095c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/LM_top_10_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9ab51bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>200618_at</th>\n",
       "      <th>200811_at</th>\n",
       "      <th>201007_at</th>\n",
       "      <th>201127_s_at</th>\n",
       "      <th>201153_s_at</th>\n",
       "      <th>201161_s_at</th>\n",
       "      <th>201207_at</th>\n",
       "      <th>201223_s_at</th>\n",
       "      <th>201225_s_at</th>\n",
       "      <th>201236_s_at</th>\n",
       "      <th>...</th>\n",
       "      <th>200868_s_at</th>\n",
       "      <th>200869_at</th>\n",
       "      <th>200871_s_at</th>\n",
       "      <th>200872_at</th>\n",
       "      <th>200874_s_at</th>\n",
       "      <th>200875_s_at</th>\n",
       "      <th>200877_at</th>\n",
       "      <th>200878_at</th>\n",
       "      <th>200879_s_at</th>\n",
       "      <th>tissue_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.8291</td>\n",
       "      <td>11.8197</td>\n",
       "      <td>10.9594</td>\n",
       "      <td>7.9837</td>\n",
       "      <td>8.2990</td>\n",
       "      <td>10.7600</td>\n",
       "      <td>7.5773</td>\n",
       "      <td>8.8964</td>\n",
       "      <td>10.8289</td>\n",
       "      <td>12.2771</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8028</td>\n",
       "      <td>14.6105</td>\n",
       "      <td>14.0292</td>\n",
       "      <td>12.6916</td>\n",
       "      <td>6.4913</td>\n",
       "      <td>9.5160</td>\n",
       "      <td>12.3179</td>\n",
       "      <td>13.9055</td>\n",
       "      <td>6.9347</td>\n",
       "      <td>airway epithelial cells obtained by bronchosco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0078</td>\n",
       "      <td>11.1135</td>\n",
       "      <td>11.2531</td>\n",
       "      <td>7.6897</td>\n",
       "      <td>10.4160</td>\n",
       "      <td>12.2918</td>\n",
       "      <td>7.3879</td>\n",
       "      <td>9.8998</td>\n",
       "      <td>10.6678</td>\n",
       "      <td>8.8367</td>\n",
       "      <td>...</td>\n",
       "      <td>8.6877</td>\n",
       "      <td>14.6908</td>\n",
       "      <td>14.6449</td>\n",
       "      <td>13.6077</td>\n",
       "      <td>6.7249</td>\n",
       "      <td>9.3521</td>\n",
       "      <td>12.2742</td>\n",
       "      <td>13.9110</td>\n",
       "      <td>6.4580</td>\n",
       "      <td>airway epithelial cells obtained by bronchosco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.8521</td>\n",
       "      <td>11.1002</td>\n",
       "      <td>11.0970</td>\n",
       "      <td>7.5435</td>\n",
       "      <td>9.7278</td>\n",
       "      <td>11.5294</td>\n",
       "      <td>7.0438</td>\n",
       "      <td>10.0822</td>\n",
       "      <td>10.4840</td>\n",
       "      <td>10.0382</td>\n",
       "      <td>...</td>\n",
       "      <td>8.1361</td>\n",
       "      <td>14.5768</td>\n",
       "      <td>13.1049</td>\n",
       "      <td>12.2742</td>\n",
       "      <td>6.3506</td>\n",
       "      <td>9.7338</td>\n",
       "      <td>12.1892</td>\n",
       "      <td>13.5563</td>\n",
       "      <td>6.2913</td>\n",
       "      <td>airway epithelial cells obtained by bronchosco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.3807</td>\n",
       "      <td>11.0173</td>\n",
       "      <td>10.7128</td>\n",
       "      <td>7.3652</td>\n",
       "      <td>10.4018</td>\n",
       "      <td>11.2197</td>\n",
       "      <td>7.3790</td>\n",
       "      <td>10.1778</td>\n",
       "      <td>11.1420</td>\n",
       "      <td>9.2288</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6369</td>\n",
       "      <td>11.9033</td>\n",
       "      <td>13.4562</td>\n",
       "      <td>12.1864</td>\n",
       "      <td>6.1411</td>\n",
       "      <td>9.1274</td>\n",
       "      <td>11.8624</td>\n",
       "      <td>13.3270</td>\n",
       "      <td>6.1857</td>\n",
       "      <td>airway epithelial cells obtained by bronchosco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.3819</td>\n",
       "      <td>11.3896</td>\n",
       "      <td>10.8832</td>\n",
       "      <td>8.0384</td>\n",
       "      <td>8.5293</td>\n",
       "      <td>11.2620</td>\n",
       "      <td>7.5531</td>\n",
       "      <td>9.9026</td>\n",
       "      <td>10.9209</td>\n",
       "      <td>11.3762</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1326</td>\n",
       "      <td>14.7207</td>\n",
       "      <td>13.6972</td>\n",
       "      <td>11.7192</td>\n",
       "      <td>6.8468</td>\n",
       "      <td>9.8641</td>\n",
       "      <td>12.5031</td>\n",
       "      <td>13.6181</td>\n",
       "      <td>6.4859</td>\n",
       "      <td>airway epithelial cells obtained by bronchosco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 979 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   200618_at  200811_at  201007_at  201127_s_at  201153_s_at  201161_s_at  \\\n",
       "0    11.8291    11.8197    10.9594       7.9837       8.2990      10.7600   \n",
       "1    11.0078    11.1135    11.2531       7.6897      10.4160      12.2918   \n",
       "2    10.8521    11.1002    11.0970       7.5435       9.7278      11.5294   \n",
       "3    10.3807    11.0173    10.7128       7.3652      10.4018      11.2197   \n",
       "4    11.3819    11.3896    10.8832       8.0384       8.5293      11.2620   \n",
       "\n",
       "   201207_at  201223_s_at  201225_s_at  201236_s_at  ...  200868_s_at  \\\n",
       "0     7.5773       8.8964      10.8289      12.2771  ...       9.8028   \n",
       "1     7.3879       9.8998      10.6678       8.8367  ...       8.6877   \n",
       "2     7.0438      10.0822      10.4840      10.0382  ...       8.1361   \n",
       "3     7.3790      10.1778      11.1420       9.2288  ...       7.6369   \n",
       "4     7.5531       9.9026      10.9209      11.3762  ...       9.1326   \n",
       "\n",
       "   200869_at  200871_s_at  200872_at  200874_s_at  200875_s_at  200877_at  \\\n",
       "0    14.6105      14.0292    12.6916       6.4913       9.5160    12.3179   \n",
       "1    14.6908      14.6449    13.6077       6.7249       9.3521    12.2742   \n",
       "2    14.5768      13.1049    12.2742       6.3506       9.7338    12.1892   \n",
       "3    11.9033      13.4562    12.1864       6.1411       9.1274    11.8624   \n",
       "4    14.7207      13.6972    11.7192       6.8468       9.8641    12.5031   \n",
       "\n",
       "   200878_at  200879_s_at                                        tissue_name  \n",
       "0    13.9055       6.9347  airway epithelial cells obtained by bronchosco...  \n",
       "1    13.9110       6.4580  airway epithelial cells obtained by bronchosco...  \n",
       "2    13.5563       6.2913  airway epithelial cells obtained by bronchosco...  \n",
       "3    13.3270       6.1857  airway epithelial cells obtained by bronchosco...  \n",
       "4    13.6181       6.4859  airway epithelial cells obtained by bronchosco...  \n",
       "\n",
       "[5 rows x 979 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a043c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "889e7dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Leukemia patient sample                                          2096\n",
       "Breast tumor                                                     1365\n",
       "HumanAorticEndothelialCells                                      1014\n",
       "Lymphoblastoid_cell_line                                          817\n",
       "pre-treatment bone marrow                                         817\n",
       "PBMC                                                              550\n",
       "Blasts and mononuclear cells, AML patient                         525\n",
       "primary colorectal adenocarcinoma                                 519\n",
       "airway epithelial cells obtained by bronchoscopy and brushing     333\n",
       "colon cancer tissue                                               331\n",
       "Name: tissue_name, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tissue_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf857bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Breast': 0, 'Cardiff': 1, 'HumanAorticEndothelialCells': 2, 'Leukemia patient sample': 3, 'Lymphoblastoid cell line': 4, 'PBMC': 5, 'airway epithelial cells obtained by bronchoscopy and brushing': 6, 'colon cancer tissue': 7, 'pre-treatment bone marrow': 8, 'primary colorectal adenocarcinoma': 9}\n",
      "indexes: [(0, 5), (1, 4), (2, 9), (3, 0), (4, 2), (5, 3), (6, 8), (7, 7), (8, 1), (9, 6)]\n",
      "hahahahahahaah\n",
      "[6 6 6 ... 0 0 0]\n",
      "---------------------\n",
      "Hungarian method confusion matrix:\n",
      "\n",
      " [[1122    0    0    0    0    1    0    0    0   59]\n",
      " [   0   70    0  244    0    0    0    0    0    0]\n",
      " [   0    0 1014    0    0    0    0    0    0    0]\n",
      " [   0  776    0 1257    4   59    0    0    0    0]\n",
      " [   1    0    0    0  816    0    0    0    0    0]\n",
      " [   0   10    0    0    0  520    0   20    0    0]\n",
      " [   0    0    0    0    0    0  333    0    0    0]\n",
      " [  10    0    0    0    0    0    0    0    0  321]\n",
      " [   0    3    0    1    0    0    0    0  813    0]\n",
      " [   7    0    0    0    0    0    0    0    0  512]]\n",
      "accuracy:0.81\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "If we use (external) classification evalutation measures like F1 or \n",
    "accuracy for clustering evaluation, problems may arise. \n",
    "\n",
    "One way to fix is to perform label matching.\n",
    "\n",
    "Here we performs kmeans clustering on the Iris dataset and proceed to use \n",
    "the Hungarian (Munkres) algorithm to correct the mismatched labeling. \n",
    "'''\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from munkres import Munkres\n",
    "\n",
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "def accuracy(cm):\n",
    "    \"\"\"computes accuracy from confusion matrix\"\"\"\n",
    "    return np.trace(cm, dtype=float) / np.sum(cm)\n",
    "\n",
    "def main():\n",
    "    \"\"\"entry point\"\"\"\n",
    "    dataset = pd.read_csv('/Users/madhuri/Desktop/MasterThesis/Part1/LM_ten_for_clustering.csv') # loads the dataset\n",
    "    #data, classes = dataset.data, dataset.target # data and true labels\n",
    "    unscaled_data=dataset.drop(['tissue_name'], axis=1)\n",
    "    classes_actual=dataset['tissue_name']\n",
    "    \n",
    "    \n",
    "    #Standardizing\n",
    "    sc=StandardScaler()\n",
    "    data = sc.fit_transform(unscaled_data)\n",
    "    #encoding tissie_name\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    classes= le.fit_transform(classes_actual)\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(le_name_mapping)\n",
    "    \n",
    "    algo = KMeans(n_clusters=10, random_state = 0)\n",
    "\n",
    "    labels = algo.fit(data).labels_ # performs the algo and get the predicted labels\n",
    "    num_labels = len(np.unique(classes))\n",
    "\n",
    "    cm = confusion_matrix(classes, labels, labels=range(num_labels)) # gets the confusion matrix\n",
    "    #print (\"---------------------\\nold confusion matrix:\\n\" \\\n",
    "     #     \" %s\\naccuracy: %.2f\" % (str(cm), accuracy(cm)))\n",
    "\n",
    "    cost_matrix = make_cost_matrix(labels, classes)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(cost_matrix)\n",
    "    print(\"indexes:\", indexes)\n",
    "#     contmat = contingency_matrix(classes, labels)\n",
    "#     print(\"Here----\")\n",
    "#     print(m.compute(contmat.max()-contmat))\n",
    "    mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "    #print (\"---------------------\\nmapping:\")\n",
    "    #for old, new in mapper['iteritems']:\n",
    "    #for old, new in mapper.iteritems():\n",
    "        \n",
    "        #print (\"map: %s --> %s\" %(old, new))\n",
    "\n",
    "    new_labels = translate_clustering(labels, mapper)\n",
    "    print(\"hahahahahahaah\")\n",
    "    print(new_labels)\n",
    "    new_cm = confusion_matrix(classes, new_labels, labels=range(num_labels))\n",
    "    print (\"---------------------\\nHungarian method confusion matrix:\\n\\n\" \\\n",
    "          \" %s\\naccuracy:%.2f\" % (str(new_cm), accuracy(new_cm)))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aaa81673",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2669945440.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [44]\u001b[0;36m\u001b[0m\n\u001b[0;31m    l = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#to assign labels to new data\n",
    "def Labs( newdata,centroids ):    \n",
    "l = []\n",
    "for i in range(len(newdata)):\n",
    "    m = []\n",
    "    for j in range(n):        \n",
    "        p = np.linalg.norm(dataset[(i),:]-centroids[(j),:])\n",
    "        m.append(p)\n",
    "    po = np.argmin(m)\n",
    "    l.append(po)\n",
    "return pd.DataFrame(np.array(l) + 1,columns =['Lab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a163585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
## https://www.hungarianalgorithm.com/examplehungarianalgorithm.php ##
